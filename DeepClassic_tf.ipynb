{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# DeepClassic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Reference\n",
    "* [Asking RNNs+LTSMs: What Would Mozart Write?](http://www.wise.io/tech/asking-rnn-and-ltsm-what-would-mozart-write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## music21 UserSetting\n",
    "* http://web.mit.edu/music21/doc/tutorials/environment.html#environment\n",
    "* [music21](https://gist.github.com/Vesnica/f8862277e4e3a27593f4ca300eedf07e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Install \n",
    "\n",
    "      sudo apt install musescore scipy timidity lilypond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "us = environment.UserSettings()\n",
    "us.getSettingsPath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#us[\"musicxmlPath\"] = \"/usr/bin/gedit\"\n",
    "us[\"musicxmlPath\"] = \"/usr/bin/mscore\"\n",
    "us[\"midiPath\"] = \"/usr/bin/timidity\"\n",
    "us[\"showFormat\"] = \"lilypond\"\n",
    "us[\"writeFormat\"] = \"lilypond\"\n",
    "us[\"musescoreDirectPNGPath\"] = \"/usr/bin/mscore\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!mkdir composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "REP=\"@\\n\"\n",
    "def trim_metadata(output_path, glob_path):\n",
    "    comp_txt = open(output_path,\"w\")\n",
    "    ll = glob.glob(glob_path)\n",
    "    for song in ll:\n",
    "        lines = open(song,\"r\").readlines()\n",
    "        out = []\n",
    "        found_first = False\n",
    "        for l in lines:\n",
    "            if l.startswith(\"=\"):\n",
    "                ## new measure, replace the measure with the @ sign, not part of humdrum\n",
    "                out.append(REP)\n",
    "                found_first = True\n",
    "                continue\n",
    "            if not found_first:\n",
    "                ## keep going until we find the end of the header and metadata\n",
    "                continue\n",
    "            if l.startswith(\"!\"):\n",
    "                ## ignore comments\n",
    "                continue\n",
    "            out.append(l)\n",
    "        comp_txt.writelines(out)\n",
    "    comp_txt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get kern data from github database\n",
    "*  [automata/ana-music: Automatic analysis of classical music for generative composition](https://github.com/automata/ana-music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/automata/ana-music.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "composers = [\"mozart\",\"beethoven\",\"chopin\",\"scarlatti\",\"haydn\"]\n",
    "for composer in composers:\n",
    "    output_path = \"composer/\" + composer + \".txt\"\n",
    "    glob_path = \"ana-music/corpus/{composer}/*.krn\".format(composer=composer)\n",
    "    trim_metadata(output_path, glob_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls composer/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get Data from KernScore\n",
    "* [KernScores](http://kern.humdrum.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%mkdir kernscore\n",
    "%mkdir kernscore/bach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "for i in range(1,15+1):\n",
    "    filename = \"inven{0:02d}.krn\".format(i)\n",
    "    file = urlopen(\"http://kern.humdrum.org/cgi-bin/ksdata?l=osu/classical/bach/inventions&file=%s&f=kern\"%filename)\n",
    "    with open(\"kernscore/bach/\"+filename,'wb') as output:\n",
    "        output.write(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_path = \"composer/bach.txt\"\n",
    "glob_path = \"kernscore/bach/*.krn\"\n",
    "trim_metadata(output_path, glob_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filename = 'composer/bach.txt'\n",
    "with open(filename, 'r') as f:\n",
    "    text=f.read()\n",
    "vocab = set(text)\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@\\n4.r\\t16dL\\n.\\t16e\\n.\\t16f\\n.\\t16g\\n.\\t16a\\n.\\t16b-J\\n@\\n4.r\\t1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 11, 16, 25,  8, 19, 36,  2, 18, 10, 11, 25, 19, 36,  2, 20, 11,\n",
       "       25, 19, 36,  2, 34, 11, 25, 19, 36,  2,  4, 11, 25, 19, 36,  2, 32,\n",
       "       11, 25, 19, 36,  2, 12,  5, 37, 11, 21, 11, 16, 25,  8, 19, 36,  2,\n",
       "       22, 38, 10, 11, 25, 19, 36,  2, 12,  5, 11, 25, 19, 36,  2, 32, 11,\n",
       "       25, 19, 36,  2,  4, 11, 25, 19, 36,  2, 34, 11, 25, 19, 36,  2, 20,\n",
       "       37, 11, 21, 11, 36,  2, 17, 10, 19, 27, 34, 10, 11, 36,  2], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       n_seqs x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       n_seqs: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    # Get the batch size and number of batches we can make\n",
    "    batch_size = n_seqs * n_steps\n",
    "    n_batches = len(arr)//batch_size\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * batch_size]\n",
    "    \n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        y[:, :-1], y[:, -1] = x[:, 1:], x[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[21 11 16 25  8 19 36  2 18 10]\n",
      " [19 36  2  4  4 13 31 11 36  2]\n",
      " [36  2 22 22 38 11 25 19 36  2]\n",
      " [12 12 11 36  2 39 19 25 11 21]\n",
      " [ 2  4 11 36  2 23 19 36  2 34]\n",
      " [32 32 11 36  2 18 19 25 11 36]\n",
      " [24 15 17 38 19 36  2 34 38 37]\n",
      " [19 25 11 36  2 39 19 16 12  5]\n",
      " [18 37 11 21 11 36  2 23 10 19]\n",
      " [36  2  4 11 21 11 36  2 42 19]]\n",
      "\n",
      "y\n",
      " [[11 16 25  8 19 36  2 18 10 11]\n",
      " [36  2  4  4 13 31 11 36  2  0]\n",
      " [ 2 22 22 38 11 25 19 36  2 32]\n",
      " [12 11 36  2 39 19 25 11 21 11]\n",
      " [ 4 11 36  2 23 19 36  2 34 38]\n",
      " [32 11 36  2 18 19 25 11 36  2]\n",
      " [15 17 38 19 36  2 34 38 37 11]\n",
      " [25 11 36  2 39 19 16 12  5 28]\n",
      " [37 11 21 11 36  2 23 10 19 27]\n",
      " [ 2  4 11 21 11 36  2 42 19 27]]\n"
     ]
    }
   ],
   "source": [
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size\n",
    "\n",
    "    '''\n",
    "    ### Build the LSTM Cell\n",
    "    # Use a basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    \n",
    "    # Add dropout to the cell\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * num_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, initial_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        x: Input tensor\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells\n",
    "        out_size: Size of this softmax layer\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Reshape output so it's a bunch of rows, one row for each step for each sequence.\n",
    "    # That is, the shape should be batch_size*num_steps rows by lstm_size columns\n",
    "    seq_output = tf.concat(lstm_output, axis=1)\n",
    "    x = tf.reshape(seq_output, [-1, in_size])\n",
    "    \n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size), stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits, name='predictions')\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, num_classes):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # One-hot encode targets and reshape to match logits, one row per batch_size per step\n",
    "    y_one_hot = tf.one_hot(targets, num_classes)\n",
    "    y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False):\n",
    "    \n",
    "        # When we're using this network for sampling later, we'll be passing in\n",
    "        # one character at a time, so providing an option for that\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size, num_steps)\n",
    "\n",
    "        # Build the LSTM cell\n",
    "        cell, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob)\n",
    "\n",
    "        ### Run the data through the RNN layers\n",
    "        # First, one-hot encode the input tokens\n",
    "        x_one_hot = tf.one_hot(self.inputs, num_classes)\n",
    "        \n",
    "        # Run each sequence step through the RNN and collect the outputs\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Get softmax predictions and logits\n",
    "        self.prediction, self.logits = build_output(outputs, lstm_size, num_classes)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss = build_loss(self.logits, self.targets, lstm_size, num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100        # Sequences per batch\n",
    "num_steps = 100         # Number of sequence steps per batch\n",
    "lstm_size = 512         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "learning_rate = 0.001   # Learning rate\n",
    "keep_prob = 0.5         # Dropout keep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20...  Training Step: 1...  Training loss: 3.7573...  3.3294 sec/batch\n",
      "Epoch: 1/20...  Training Step: 2...  Training loss: 3.6305...  3.2960 sec/batch\n",
      "Epoch: 1/20...  Training Step: 3...  Training loss: 3.2176...  3.2646 sec/batch\n",
      "Epoch: 1/20...  Training Step: 4...  Training loss: 3.2395...  3.2596 sec/batch\n",
      "Epoch: 2/20...  Training Step: 5...  Training loss: 3.2303...  3.2477 sec/batch\n",
      "Epoch: 2/20...  Training Step: 6...  Training loss: 3.0707...  3.2408 sec/batch\n",
      "Epoch: 2/20...  Training Step: 7...  Training loss: 3.0182...  3.2367 sec/batch\n",
      "Epoch: 2/20...  Training Step: 8...  Training loss: 3.0284...  3.2586 sec/batch\n",
      "Epoch: 3/20...  Training Step: 9...  Training loss: 3.0550...  3.2530 sec/batch\n",
      "Epoch: 3/20...  Training Step: 10...  Training loss: 2.9846...  3.2664 sec/batch\n",
      "Epoch: 3/20...  Training Step: 11...  Training loss: 2.9887...  3.2661 sec/batch\n",
      "Epoch: 3/20...  Training Step: 12...  Training loss: 2.9697...  3.2426 sec/batch\n",
      "Epoch: 4/20...  Training Step: 13...  Training loss: 3.0143...  3.2542 sec/batch\n",
      "Epoch: 4/20...  Training Step: 14...  Training loss: 2.9604...  3.2602 sec/batch\n",
      "Epoch: 4/20...  Training Step: 15...  Training loss: 2.9643...  3.2561 sec/batch\n",
      "Epoch: 4/20...  Training Step: 16...  Training loss: 2.9476...  3.2715 sec/batch\n",
      "Epoch: 5/20...  Training Step: 17...  Training loss: 2.9785...  3.2682 sec/batch\n",
      "Epoch: 5/20...  Training Step: 18...  Training loss: 2.9299...  3.2636 sec/batch\n",
      "Epoch: 5/20...  Training Step: 19...  Training loss: 2.9485...  3.2429 sec/batch\n",
      "Epoch: 5/20...  Training Step: 20...  Training loss: 2.9270...  3.2504 sec/batch\n",
      "Epoch: 6/20...  Training Step: 21...  Training loss: 2.9468...  3.2498 sec/batch\n",
      "Epoch: 6/20...  Training Step: 22...  Training loss: 2.9023...  3.2578 sec/batch\n",
      "Epoch: 6/20...  Training Step: 23...  Training loss: 2.9239...  3.2249 sec/batch\n",
      "Epoch: 6/20...  Training Step: 24...  Training loss: 2.9043...  3.2347 sec/batch\n",
      "Epoch: 7/20...  Training Step: 25...  Training loss: 2.9205...  3.2395 sec/batch\n",
      "Epoch: 7/20...  Training Step: 26...  Training loss: 2.8810...  3.2568 sec/batch\n",
      "Epoch: 7/20...  Training Step: 27...  Training loss: 2.8955...  3.2520 sec/batch\n",
      "Epoch: 7/20...  Training Step: 28...  Training loss: 2.8834...  3.2722 sec/batch\n",
      "Epoch: 8/20...  Training Step: 29...  Training loss: 2.9040...  3.2539 sec/batch\n",
      "Epoch: 8/20...  Training Step: 30...  Training loss: 2.9072...  3.2577 sec/batch\n",
      "Epoch: 8/20...  Training Step: 31...  Training loss: 2.8838...  3.2650 sec/batch\n",
      "Epoch: 8/20...  Training Step: 32...  Training loss: 2.8714...  3.2529 sec/batch\n",
      "Epoch: 9/20...  Training Step: 33...  Training loss: 2.8831...  3.2522 sec/batch\n",
      "Epoch: 9/20...  Training Step: 34...  Training loss: 2.8462...  3.2631 sec/batch\n",
      "Epoch: 9/20...  Training Step: 35...  Training loss: 2.8671...  3.2755 sec/batch\n",
      "Epoch: 9/20...  Training Step: 36...  Training loss: 2.8423...  3.2609 sec/batch\n",
      "Epoch: 10/20...  Training Step: 37...  Training loss: 2.8616...  3.2723 sec/batch\n",
      "Epoch: 10/20...  Training Step: 38...  Training loss: 2.8246...  3.2707 sec/batch\n",
      "Epoch: 10/20...  Training Step: 39...  Training loss: 2.8439...  3.2640 sec/batch\n",
      "Epoch: 10/20...  Training Step: 40...  Training loss: 2.8117...  3.2401 sec/batch\n",
      "Epoch: 11/20...  Training Step: 41...  Training loss: 2.8126...  3.2461 sec/batch\n",
      "Epoch: 11/20...  Training Step: 42...  Training loss: 2.7867...  3.2667 sec/batch\n",
      "Epoch: 11/20...  Training Step: 43...  Training loss: 2.7912...  3.2490 sec/batch\n",
      "Epoch: 11/20...  Training Step: 44...  Training loss: 2.7573...  3.2674 sec/batch\n",
      "Epoch: 12/20...  Training Step: 45...  Training loss: 2.7654...  3.2542 sec/batch\n",
      "Epoch: 12/20...  Training Step: 46...  Training loss: 2.7199...  3.2647 sec/batch\n",
      "Epoch: 12/20...  Training Step: 47...  Training loss: 2.7411...  3.2366 sec/batch\n",
      "Epoch: 12/20...  Training Step: 48...  Training loss: 2.7082...  3.2552 sec/batch\n",
      "Epoch: 13/20...  Training Step: 49...  Training loss: 2.8104...  3.2698 sec/batch\n",
      "Epoch: 13/20...  Training Step: 50...  Training loss: 2.6495...  3.2316 sec/batch\n",
      "Epoch: 13/20...  Training Step: 51...  Training loss: 2.7089...  3.2654 sec/batch\n",
      "Epoch: 13/20...  Training Step: 52...  Training loss: 2.6454...  3.2728 sec/batch\n",
      "Epoch: 14/20...  Training Step: 53...  Training loss: 2.6250...  3.2549 sec/batch\n",
      "Epoch: 14/20...  Training Step: 54...  Training loss: 2.5933...  3.2537 sec/batch\n",
      "Epoch: 14/20...  Training Step: 55...  Training loss: 2.5918...  3.2564 sec/batch\n",
      "Epoch: 14/20...  Training Step: 56...  Training loss: 2.5423...  3.2496 sec/batch\n",
      "Epoch: 15/20...  Training Step: 57...  Training loss: 2.5267...  3.2542 sec/batch\n",
      "Epoch: 15/20...  Training Step: 58...  Training loss: 2.4726...  3.2641 sec/batch\n",
      "Epoch: 15/20...  Training Step: 59...  Training loss: 2.4739...  3.2766 sec/batch\n",
      "Epoch: 15/20...  Training Step: 60...  Training loss: 2.3928...  3.2407 sec/batch\n",
      "Epoch: 16/20...  Training Step: 61...  Training loss: 2.3872...  3.2699 sec/batch\n",
      "Epoch: 16/20...  Training Step: 62...  Training loss: 2.3099...  3.3094 sec/batch\n",
      "Epoch: 16/20...  Training Step: 63...  Training loss: 2.4396...  3.2648 sec/batch\n",
      "Epoch: 16/20...  Training Step: 64...  Training loss: 2.3358...  3.2857 sec/batch\n",
      "Epoch: 17/20...  Training Step: 65...  Training loss: 2.2880...  3.2413 sec/batch\n",
      "Epoch: 17/20...  Training Step: 66...  Training loss: 2.1907...  3.2685 sec/batch\n",
      "Epoch: 17/20...  Training Step: 67...  Training loss: 2.2355...  3.2450 sec/batch\n",
      "Epoch: 17/20...  Training Step: 68...  Training loss: 2.1492...  3.2673 sec/batch\n",
      "Epoch: 18/20...  Training Step: 69...  Training loss: 2.1446...  3.2600 sec/batch\n",
      "Epoch: 18/20...  Training Step: 70...  Training loss: 2.0611...  3.2582 sec/batch\n",
      "Epoch: 18/20...  Training Step: 71...  Training loss: 2.0620...  3.2575 sec/batch\n",
      "Epoch: 18/20...  Training Step: 72...  Training loss: 2.0036...  3.2497 sec/batch\n",
      "Epoch: 19/20...  Training Step: 73...  Training loss: 2.0490...  3.2814 sec/batch\n",
      "Epoch: 19/20...  Training Step: 74...  Training loss: 2.0179...  3.2614 sec/batch\n",
      "Epoch: 19/20...  Training Step: 75...  Training loss: 1.9919...  3.2601 sec/batch\n",
      "Epoch: 19/20...  Training Step: 76...  Training loss: 1.9168...  3.2572 sec/batch\n",
      "Epoch: 20/20...  Training Step: 77...  Training loss: 1.9232...  3.2483 sec/batch\n",
      "Epoch: 20/20...  Training Step: 78...  Training loss: 1.8438...  3.2540 sec/batch\n",
      "Epoch: 20/20...  Training Step: 79...  Training loss: 1.8598...  3.2681 sec/batch\n",
      "Epoch: 20/20...  Training Step: 80...  Training loss: 1.7912...  3.2735 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "# Save every N iterations\n",
    "save_every_n = 200\n",
    "\n",
    "model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Use the line below to load a checkpoint and resume training\n",
    "    #saver.restore(sess, 'checkpoints/______.ckpt')\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Train network\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            \n",
    "            end = time.time()\n",
    "            print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                  'Training Step: {}... '.format(counter),\n",
    "                  'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                  '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "    \n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/i80_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i80_l512.ckpt\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \"):\n",
    "    samples = [c for c in prime]\n",
    "    model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/i80_l512.ckpt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@\n",
      ".1A6\t1ddc#\n",
      "16\t\t\n",
      "ec\n",
      "\t16dc\t16\n",
      "\t16d\n",
      "16A\t16ed\n",
      "1BB\t16f\n",
      "\n",
      "16B\t..166-\n",
      "16A\t\t\n",
      "cecc16c\t.\n",
      "16B\t\t6\n",
      "\n",
      "16\t\t8e\n",
      "@16G\t.16e\n",
      "116\t#..166c#\n",
      "611\tf\n",
      ".16e\t16e\n",
      "16G\t.\n",
      "16e-\t16d\n",
      "16B\t.16f\n",
      "1\tdd16f\n",
      "816\t16\n",
      "16\t.\n",
      "16A\t16cc.\n",
      "16\t-#\n",
      "8A\t\t6c\n",
      "8@\t8\n",
      "16A\t..16c\t#16\n",
      "\n",
      "8B\t16fc\n",
      "16B\t8dd16e-\t16de\n",
      "16G\t16c-\n",
      "16G\t.16ec\n",
      "16\te16d\n",
      ".\t16e-#8\n",
      "16\t16dc\n",
      "16B\t86\n",
      "81A-\t.\n",
      "16A\t\t16fc\n",
      "\n",
      "6\t16a\n",
      "16F\t.16g\n",
      "16A\t8\n",
      "\n",
      "B\tAd\n",
      "8\t\t.\n",
      "8c\t8\n",
      ".\t16e\n",
      ".\t16ed\n",
      "8A\t16fd\n",
      "816\t\t\n",
      "d\n",
      "16AA\t..16fd8\n",
      "16\t-#\n",
      ".\t16ge\n",
      "\n",
      "\t66c#.\n",
      "16A\t\t6c\n",
      "\n",
      "16\t\t.\n",
      "116A.\t8\n",
      "16e\t8.\n",
      "8A\t16g#..\n",
      "16A\t16d\n",
      "\t16ce\n",
      ".16B\t8c\n",
      "16G\t.\n",
      "66\t16c\n",
      "\n",
      "16\t\t.\n",
      "16cB\t8\n",
      "16B\t\t\n",
      "c16c#\t.\n",
      "16G\t..616d\t16ee\n",
      "16\t-\n",
      "16\t#\n",
      "16B\t\n",
      "16B\t\n",
      "6e16B\t16d#\n",
      "16\t\t16d\n",
      ".16\t#16c#\n",
      "\t116c\t.\n",
      "16B--\t16d-\n",
      "116\t#\n",
      "16A\t16d\n",
      "\t16c-.816d-\t16e\n",
      "\n",
      "16G\t\t6fd\n",
      "16F\t\t16f\n",
      ".16A\t16c-\n",
      "16F\t16d\n",
      "16A\t16d\n",
      ".16B\t16e\n",
      "8\t16f\n",
      "\n",
      "\t66e\n",
      ".\t16ed\n",
      ".16\t16e\n",
      ".\t16ec\n",
      "\t66c\n",
      ".16\t\t\n",
      "1dc\n",
      ".16A.\t16fc\n",
      "16\t\t16\n",
      "e\n",
      ".\t16c#\n",
      "16\t1dd\n",
      "16F\t16d-16c\n",
      "16A\t16f-\n",
      "\n",
      "6\t16f-\n",
      ".1AB\t16e\n",
      ".\t16e#\n",
      "8\t16ee\n",
      ".\t16de\n",
      "\t61ec\n",
      ".\t16c#.\n",
      "16\t16d\n",
      "16\t16e\n",
      "16B\t.16c#\n",
      "16G\t16c-\n",
      "16\t-\n",
      "16B\t16f\n",
      "16B\t16f\n",
      "\t16d\n",
      "816B\t16d\n",
      "\n",
      "\t6e-16c\t16\n",
      "#16B\t16c#\t16e-\n",
      "\t16dd\n",
      "16G\t16d\n",
      "16F\t16fc\n",
      "16AA\t16d-.16c\t16de\n",
      "16A-\t16c\n",
      "16\t-\n",
      "16c#\t1dd\n",
      "16A\t#16c\n",
      "\t16ee\n",
      ".16F\t.16f\n",
      "\t6ee\n",
      "16B\t\t16fc\n",
      "8\t1Bfd.\n",
      "16F\t.8d1edc\n",
      ".6A\t16f\n",
      ".\t616e\n",
      "8\t16f\n",
      ".\n",
      "\t16gc\n",
      ".16G\t8\n",
      "16\t.\n",
      "8B\t16d\n",
      ".\t16dc#\n",
      "\n",
      "6\t\t16e\n",
      "-\t16ec\n",
      "16\t\t8\n",
      "cc16--8\n",
      ".\t16cd\n",
      "\n",
      "\t61ec\n",
      "8\t16a-\n",
      ".\t16e-\n",
      "16\t.\n",
      "6d1A\t16c\n",
      ".\t16d#\n",
      "8\t16a-\n",
      "16G\t\t6\n",
      "16A\t\t\n",
      "6e\n",
      ".A\t16e#\n",
      ".\t\t16c#\n",
      "\n",
      "8\t\t16c\n",
      "..\t16dc\n",
      "8\t6ec\n",
      "16\t8\n",
      "8.\t16dc\n",
      "81G\t16dd\n",
      ".\t16fe-\n",
      "16B\t8\n",
      "c16-\t\n",
      "66\t16c#\n",
      "16\t#1dc\n",
      "86\t16ed1.\t\n",
      "16d\t.16e#\n",
      "16\t-\t\n",
      "6ec\n",
      "16B\t\t6\n",
      "16B\t.\n",
      "16A\t.6\n",
      "@1BGA\t8ec\n",
      "16\t\t\n",
      "16f#\t\n",
      "16e\t16e\n",
      "\n",
      "6B\t\t6c\n",
      "86B\t\t16e\n",
      "\n",
      "\t6\t1ecd\n",
      "8B16\t.16ed\n",
      "816\t.8c\n",
      "16A\t.\n",
      "16B\t.\n",
      "16e\t16d\n",
      ".16F\t116c#\n",
      "16A\t16c\n",
      "16A\t16d\n",
      "16G\t16c\n",
      "\n",
      "616\t\t\n",
      "d\n",
      "16G\t.\n",
      "16B\t.\n",
      "\n",
      "6G\t\t6f\n",
      ".\n",
      "1\t6#\n",
      "88\t\t16f\n",
      ".\t.16ee#\n",
      "16\t#8..16ee\t\n",
      "81AB\t\n",
      "8d\t.\n",
      "16c\t\n",
      ".\t16c\n",
      ".\t.6d16f#\n",
      ".\t16de\n",
      "\t61d-#\n",
      "16\t.\n",
      "16B\t16e\n",
      ".\t16d#\n",
      "81G\t.86\n",
      "16\t-.\n",
      "16\t#16e-\n",
      "16A\t16f\n",
      "16F\t.16f\n",
      "816\t16\n",
      ".\n",
      "16A\t..16cc\n",
      "\n",
      "16G\t\t\n",
      "\n",
      "6F\t.\t16f-\n",
      ".116-\t.\n",
      "616BB\t16d\n",
      ".\t6ee\n",
      "\n",
      "6\t16f#\n",
      "\n",
      "\tBB-16\t\n",
      ".116\t\t.\n",
      "16d-#116d\t.\n",
      "16G\t86\n",
      "16G\t\t\n",
      "6c-\n",
      "16A\t16e\n",
      "16A\t.16e--16c-\n",
      "16B\t816-c\n",
      "16G\t16a\n",
      "16\t\t16c\n",
      "8\n",
      "\t16cc\t.\n",
      "16G\t#6\n",
      "1A\t\t6\n",
      "\n",
      "\t16c\t8\n",
      ".B\t16c-#\t\n",
      "6A\t16dc\n",
      ".16A\t\t16ed\n",
      ".16B\t.1de\n",
      "16\t\t\n",
      "6d\n",
      "1\t6##.\n",
      "16B\t.6\n",
      "\n",
      "6\tA\td\n",
      "\n",
      "16\t#\t.\n",
      "86G\t.16c\n",
      "\t.16c-\t16d\n",
      "\t616#\t\n",
      "16c\t.\n",
      "16B-\t16c\n",
      "16B\t\t1cc\n",
      "\n",
      "16\t-#\n",
      "\n",
      "6\t\t6c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "samp = sample(checkpoint, 2000, lstm_size, len(vocab), prime=\"@\\n\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"results/m1a.krn\",\"r\").readlines()\n",
    "r = []\n",
    "bar = 1\n",
    "for l in f:\n",
    "    if l.startswith(\"@\"):\n",
    "        if bar == 1:\n",
    "            r.append(\"=1-\\t=1-\\t=1-\\n\")\n",
    "        else:\n",
    "            r.append(\"={bar}\\t={bar}\\t={bar}\\n\".format(bar=bar))\n",
    "        bar += 1\n",
    "    else:\n",
    "        r.append(l)\n",
    "open(\"results/m1a-bar.krn\",\"w\").writelines(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-a66211951447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmusic21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results/m1a-bar.krn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(value, *args, **keywords)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         return parseFile(value, number=number, format=m21Format, \n\u001b[0;32m-> 1087\u001b[0;31m                          forceSource=forceSource, **keywords)\n\u001b[0m\u001b[1;32m   1088\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         return parseFile(common.cleanpath(value), number=number, format=m21Format, \n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforceSource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(self, fp, number, format, forceSource, storePickle, **keywords)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0menvironLocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintDebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading original version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFileNoPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwritePickle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfpPickle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstorePickle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0;31m# save the stream to disk...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparseFileNoPickle\u001b[0;34m(self, fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetSubconverterFromFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0museFormat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileNumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/converter/subConverters.py\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(self, filepath, number)\u001b[0m\n\u001b[1;32m    543\u001b[0m         '''\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mmusic21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhumdrum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhumdrum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;31m#self.data.stream.makeNotation()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/humdrum/__init__.py\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mMost\u001b[0m \u001b[0musers\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     '''\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mspineParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHumdrumFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparseData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/humdrum/spineParser.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    756\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin-1\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhumFH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meventList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhumFH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhumFH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/humdrum/spineParser.py\u001b[0m in \u001b[0;36mparseFH\u001b[0;34m(self, fileHandle)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileHandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mspineDataCollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspineDataCollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHumdrumLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/humdrum/spineParser.py\u001b[0m in \u001b[0;36mparseLines\u001b[0;34m(self, dataStream)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsePositionInStream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseEventListFromDataStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataStream\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sets self.eventList and fileLength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsePositionInStream\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileLength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/humdrum/spineParser.py\u001b[0m in \u001b[0;36mparseEventListFromDataStream\u001b[0;34m(self, dataStream)\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mcontinue\u001b[0m \u001b[0;31m# technically forbidden by Humdrum but the source of so many errors!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\!\\!\\!'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meventList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlobalReferenceLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsePositionInStream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\!\\!'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m## find global comments at the top of the line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meventList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlobalCommentLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsePositionInStream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dclassic/lib/python3.6/site-packages/music21/humdrum/spineParser.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, position, contents)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0mnoExclaim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'^\\!\\!\\!+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoExclaim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "from music21 import *\n",
    "m1 = converter.parse(\"results/m1a-bar.krn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "21px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
